{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1xH50-V37IOAjM_bo5EP6LEBczIx7BpQu","authorship_tag":"ABX9TyOztS7fKq+MlZgeZcvuD/0W"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Underfitting e Overfitting\n","\n","Agora iremos abordar o conceito de Underfitting e Overfitting."],"metadata":{"id":"NxOVSFWEa2l0"}},{"cell_type":"markdown","source":["Utilizando como exemplo o modelo que adotamos, a árvore de decisão, temos que ela se ramifica a cada decisão que ela deve tomar. Não é comum uma árvore ter mais do que 10 ramificações. Ou seja, caso você tenha 10 ramificações e cada ramificações gerando duas folhas, você terá 2 elevado a 10, resultando em 1024 folhas. \n","\n","Esta grande ramificação, gera uma baixa quantidade de dados em cada ramificação, podendo gerar **overfitting (ou sobreajuste)**. Aparentemente este modelo parece ser perfeito com os dados treinados, mas ao testar nos dados de validação, o resultado será bem diferente de quando treinado, gerando resultados muito fora da realidade.\n","\n"],"metadata":{"id":"RBvdtU49Y0XF"}},{"cell_type":"markdown","source":["Se tivermos uma quantidade de ramificações muito baixa, isto resulta em uma grande quantidade de dados em cada folha. Essa grande quantidade de dados, pode gerar resultados falhos por não ter uma boa distinção de características e padrões. Isto se chama **underfitting ou subajuste**."],"metadata":{"id":"hXvR4ablbjmA"}},{"cell_type":"markdown","source":["Então o que procuramos, é o meio termo entre o overfitting e underfitting."],"metadata":{"id":"D7eNvvjuclzc"}},{"cell_type":"code","execution_count":13,"metadata":{"id":"OpM4zQBsapnl","executionInfo":{"status":"ok","timestamp":1686355600659,"user_tz":180,"elapsed":273,"user":{"displayName":"Manusa Leal","userId":"14886334780301917701"}}},"outputs":[],"source":["from sklearn.tree import DecisionTreeRegressor\n","from sklearn.metrics import mean_absolute_error\n","\n","def resultado_mae(max_folhas, treino_X, val_X, treino_y, val_y):\n","  #Escolha do modelo\n","  modelo=DecisionTreeRegressor(max_leaf_nodes=max_folhas, random_state=0)\n","  #Ajuste do modelo\n","  modelo.fit(treino_X, treino_y)\n","  #Predição\n","  predicao_val=modelo.predict(val_X)\n","  #Validação\n","  mae=mean_absolute_error(val_y,predicao_val)\n","  return mae \n"]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","file_path='/content/drive/MyDrive/Data Science/notebooks/Intro_to_Machine_Learning_Kagle/melbourne-housing-snapshot/melb_data.csv'\n","\n","#Leitura e armazenamento dos dados csv no DataFrame intitulado dados_melbourne\n","dados_melbourne=pd.read_csv(file_path)\n","\n","#Remoção de valores vazios\n","dados_melbourne=dados_melbourne.dropna(axis=0) \n","\n","#Alvo de predição\n","y=dados_melbourne.Price \n","\n","#Selecionando as características\n","X=dados_melbourne[['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', \n","                   'YearBuilt', 'Lattitude', 'Longtitude']] \n","\n","treino_X, val_X, treino_y, val_y=train_test_split(X, y, random_state=0)"],"metadata":{"id":"9YB9nM4llQuF","executionInfo":{"status":"ok","timestamp":1686355511907,"user_tz":180,"elapsed":335,"user":{"displayName":"Manusa Leal","userId":"14886334780301917701"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["Agora vamos testar a nossa função de acurácia para diferentes quantidades de folhas das ramificações (ou seja, vamos fazer um loop):"],"metadata":{"id":"vStfy3yripcm"}},{"cell_type":"code","source":["for max_folhas in [5, 50, 500, 5000]:\n","  mae=resultado_mae(max_folhas, treino_X, val_X, treino_y, val_y)\n","  print(\"Número máximo de folhas de ramificações: {0:d} \\t\\t Mean Absolute Error: {1:.2f}\".format(max_folhas, mae))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LflNdrBxj5wG","executionInfo":{"status":"ok","timestamp":1686356594033,"user_tz":180,"elapsed":301,"user":{"displayName":"Manusa Leal","userId":"14886334780301917701"}},"outputId":"9682afe3-ff7a-4d3f-9afe-d5a0a448b73f"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Número máximo de folhas de ramificações: 5 \t\t Mean Absolute Error: 347380.34\n","Número máximo de folhas de ramificações: 50 \t\t Mean Absolute Error: 258171.21\n","Número máximo de folhas de ramificações: 500 \t\t Mean Absolute Error: 243495.96\n","Número máximo de folhas de ramificações: 5000 \t\t Mean Absolute Error: 255575.13\n"]}]},{"cell_type":"markdown","source":["Quando utilizamos o MAE, esperamos encontrar o menor erro absoluto médio. O menor MAE foi de 243495.96. \n","\n","Logo, podemos concluir que o número máximo de folhas de ramificações (testado) que produz maior acurácia é o de 500 folhas.\n","\n","O último caso, de 5000 folhas de ramificações, acaba sendo interessante, pois entra no que foi falado no começo deste capítulo sobre um número muito alto de folhas (>1024) causar overfitting. Ao validar o modelo, o MAE consequentemente aumenta por conta deste fator. "],"metadata":{"id":"dIonsX-8rr8R"}}]}