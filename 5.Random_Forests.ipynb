{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1nWPS1A55QQ2kcsYW7cKFARNEt1km5qlS","authorship_tag":"ABX9TyPIKg/tX2bklLIQf1Y57DIW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Random Forests\n","\n","Vimos que dependendo do número de folhas e ramificações, podemos ter um modelo apropriado, sobreajustado e subajustado.\n","\n","Agora iremos explorar o Random Forest, que através da média de predição de cada componente da árvore, retorna a melhor predição para nós. Vamos ao exemplo!"],"metadata":{"id":"zh_xTTuv3eVV"}},{"cell_type":"markdown","source":["Primeiro vamos encontrar o nosso alvo de predição, características, dados de treino e validação:"],"metadata":{"id":"ntmT9JQx46OG"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"-DPiqrDLvaCS","executionInfo":{"status":"ok","timestamp":1686359990553,"user_tz":180,"elapsed":3579,"user":{"displayName":"Manusa Leal","userId":"14886334780301917701"}}},"outputs":[],"source":["\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","file_path='/content/drive/MyDrive/Data Science/notebooks/Intro_to_Machine_Learning_Kagle/melbourne-housing-snapshot/melb_data.csv'\n","\n","#Leitura e armazenamento dos dados csv no DataFrame intitulado dados_melbourne\n","dados_melbourne=pd.read_csv(file_path)\n","\n","#Remoção de valores vazios\n","dados_melbourne=dados_melbourne.dropna(axis=0) \n","\n","#Alvo de predição\n","y=dados_melbourne.Price \n","\n","#Selecionando as características\n","X=dados_melbourne[['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', \n","                        'YearBuilt', 'Lattitude', 'Longtitude']] \n","\n","treino_X, val_X, treino_y, val_y=train_test_split(X, y, random_state=0)"]},{"cell_type":"markdown","source":["Agora vamos ao nosso modelo de Árvore de Decisão utilizando a classe Random Forest:"],"metadata":{"id":"P9oOy9yQ5HR6"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_absolute_error\n","\n","#Modelo escolhido\n","modelo_forest=RandomForestRegressor(random_state=1)\n","\n","#Ajuste do modelo\n","modelo_forest.fit(treino_X,treino_y)\n","\n","#Predição\n","predict_modelo=modelo_forest.predict(val_X)\n","\n","#Validação (Acurácia)\n","print(mean_absolute_error(val_y,predict_modelo))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cLP1cLEB5Xk6","executionInfo":{"status":"ok","timestamp":1686360405004,"user_tz":180,"elapsed":2846,"user":{"displayName":"Manusa Leal","userId":"14886334780301917701"}},"outputId":"2d8b65fa-fc07-4159-c009-71f6e5a44442"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["191669.7536453626\n"]}]},{"cell_type":"markdown","source":["Logo, o MAE encontrado utilizando o Random Forests foi menor do que no capítulo 4, onde escolhemos valores arbitrários, resultando em maior acurácia.\n","\n","\n","\n","---\n","\n"],"metadata":{"id":"SuY-hWTH6gG6"}},{"cell_type":"markdown","source":["Terminamos por aqui os estudos de Introdução a ML disponibilizado pelo Kaggle.\n","\n","Espero que tenham gostado!"],"metadata":{"id":"pcYtFERD63Qd"}}]}